{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import FreqDist\n",
    "from sklearn.feature_selection import SelectKBest, SelectFdr\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "class Chi2Anlaysis(object):\n",
    "    # X^2 is statistically significant at the p-value level\n",
    "    def __init__(self,X, Y, feature_names):\n",
    "        self.X=X\n",
    "        self.Y=Y\n",
    "        self.feature_names=feature_names\n",
    "        \n",
    "    def extract_features_kbest(self, N):\n",
    "        \n",
    "        selector = SelectKBest(chi2,k='all')\n",
    "        selector.fit_transform(self.X, self.Y )\n",
    "        scores = {self.feature_names[i]: (x,selector.pvalues_[i]) for i, x in enumerate(list(selector.scores_))}\n",
    "        scores = sorted(scores.items(), key=lambda x: x[1][0], reverse=True)[0:N]\n",
    "        f = codecs.open('test_kbest.txt','w')\n",
    "        f.write('\\t'.join(['feature', 'score', 'p-value', '# I', '# O'])+'\\n')\n",
    "        for w, score in scores:\n",
    "            feature_array=self.X[:,self.feature_names.index(w)]\n",
    "            pos=[feature_array[idx] for idx, x in enumerate(self.Y) if x==1]\n",
    "            neg=[feature_array[idx] for idx, x in enumerate(self.Y) if x==0]\n",
    "            f.write('\\t'.join([str(w), str(score[0]), str(score[1]), str(round(np.average(pos),2))+'(+/-)'+str(round(np.std(pos),2)), str(round(np.average(neg),2))+'(+/-)'+str(round(np.std(neg),2))])+'\\n')        \n",
    "        f.close()\n",
    "    \n",
    "    def extract_features_fdr(self, N):\n",
    "        #https://brainder.org/2011/09/05/fdr-corrected-fdr-adjusted-p-values/\n",
    "        #Filter: Select the p-values for an estimated false discovery rate\n",
    "        #This uses the Benjamini-Hochberg procedure. alpha is an upper bound on the expected false discovery rate.\n",
    "        selector = SelectFdr(chi2,alpha=5e-2)\n",
    "        selector.fit_transform(self.X, self.Y )\n",
    "        scores = {self.feature_names[i]: (x,selector.pvalues_[i]) for i, x in enumerate(list(selector.scores_))}\n",
    "        scores = sorted(scores.items(), key=lambda x: x[1][1])[0:N]\n",
    "        f = codecs.open('test_fdr.txt','w')\n",
    "        f.write('\\t'.join(['feature', 'score', 'p-value', 'avg I', 'avg O'])+'\\n')\n",
    "        for w, score in scores:\n",
    "            feature_array=self.X[:,self.feature_names.index(w)]\n",
    "            pos=[feature_array[idx] for idx, x in enumerate(self.Y) if x==1]\n",
    "            neg=[feature_array[idx] for idx, x in enumerate(self.Y) if x==0]\n",
    "            f.write('\\t'.join([str(w), str(score[0]), str(score[1]), str(round(np.average(pos),2))+'(+/-)'+str(round(np.std(pos),2)), str(round(np.average(neg),2))+'(+/-)'+str(round(np.std(neg),2))])+'\\n')        \n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    \n",
    "class TextFeature(object):\n",
    "    def __init__(self, corpus, analyzer='word', ngram=(1,1)):\n",
    "        tfm = TfidfVectorizer(use_idf=False, analyzer=analyzer, ngram_range=ngram, norm=None, stop_words=[], lowercase=False)\n",
    "        self.tf_vec = tfm.fit_transform(corpus).toarray()\n",
    "        self.feature_names = tfm.get_feature_names()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Surah_test\n",
    "data=[(l.split()[1].split('##')[0],l.strip().split()[2::]) for l in codecs.open('test/id_quran_roots.txt','r','utf-8').readlines()]\n",
    "corpus=[' '.join(x) for y,x in data]\n",
    "label=[1 if y=='36' else 0 for y,x in data]\n",
    "CA=Chi2Anlaysis(TF.tf_vec, label,TF.feature_names)\n",
    "TF=TextFeature(corpus,ngram=(1,5))\n",
    "CA.extract_features_kbest(100)\n",
    "CA.extract_features_fdr(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A={'a':(2.00,2),'d':(1.00,0.5),'c':(23,0.1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_x = sorted(A.items(), key=operator.itemgetter([1][0]),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "2.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for x,y in sorted_x:\n",
    "    print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
