{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__copyright__ = \"Copyright 2017, HH-HZI Project\"\n",
    "__author__ = \"Ehsaneddin Asgari\"\n",
    "__license__ = \"GPL\"\n",
    "__version__ = \"1.0.0\"\n",
    "__maintainer__ = \"Ehsaneddin Asgari\"\n",
    "__email__ = \"asgari@berkeley.edu ehsaneddin.asgari@helmholtz-hzi.de\"\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "from data_access.data_access_utility import ABRDataAccess\n",
    "from Bio import Phylo\n",
    "import numpy as np\n",
    "import itertools\n",
    "from multiprocessing import Pool\n",
    "import tqdm\n",
    "from utility.file_utility import FileUtility\n",
    "from utility.featurizer import TextFeature\n",
    "from chi2analysis.chi2analysis import Chi2Analysis\n",
    "\n",
    "\n",
    "class PhyloChi2(object):\n",
    "\n",
    "    def __init__(self, nwk_file, X, Y, feature_list, sample_list,saving_path='', resulting_path=''):\n",
    "        '''\n",
    "            PhyloChi2\n",
    "        '''\n",
    "        # data reading\n",
    "        self.saving_path = saving_path\n",
    "        self.resulting_path = resulting_path\n",
    "        # read features\n",
    "        self.tree = Phylo.read(nwk_file, \"newick\")\n",
    "        self.X=X\n",
    "        self.Y=Y\n",
    "        self.features=feature_list\n",
    "        self.isolates=sample_list\n",
    "        # extract edges\n",
    "        self.extract_all_edges()\n",
    "\n",
    "    def generate_parallel_gainloss_data_for_drug(self, num_p):\n",
    "        '''\n",
    "           for using num_p\n",
    "           generates the data for chi2 in self.gainloss_corpus and self.gainloss_labels\n",
    "        '''\n",
    "\n",
    "        pool = Pool(processes=num_p)\n",
    "\n",
    "        # prepare dictionary\n",
    "        gains_losses_corpus = []\n",
    "        for g_l_c in tqdm.tqdm(pool.imap_unordered(self.get_corpus_labels, self.all_edges, chunksize=1),\n",
    "                               total=len(self.all_edges)):\n",
    "            gains_losses_corpus += g_l_c\n",
    "\n",
    "        lines = [' '.join(l[1::]) for l in gains_losses_corpus]\n",
    "        labels = [l[0] for l in gains_losses_corpus]\n",
    "        TF = TextFeature(lines)\n",
    "        FileUtility.save_sparse_csr(self.saving_path + '_'.join([ 'gainlosses', 'X']),\n",
    "                                    TF.tf_vec)\n",
    "        FileUtility.save_list(self.saving_path + '_'.join([ 'gainlosses', 'features']),\n",
    "                              TF.feature_names)\n",
    "        FileUtility.save_list(self.saving_path + '_'.join([ 'gainlosses', 'lables']), labels)\n",
    "\n",
    "    def extract_all_edges(self):\n",
    "        '''\n",
    "            extract all edges\n",
    "        '''\n",
    "        terminals = self.tree.get_terminals()\n",
    "        all_edges = list()\n",
    "        for t in terminals:\n",
    "            all_edges.append(PhyloChi2.get_path_edges(self.tree.get_path(t)))\n",
    "        # check if the edge is meaningful (not having unknown differences)\n",
    "        all_edges = [(A, B) for A, B in list(itertools.chain(*all_edges)) if\n",
    "                          len([x for x in B if x in self.isolates]) > 0 and len(\n",
    "                              [x for x in A if x in self.isolates]) > 0 and (\n",
    "                          not [x for x in A if x in self.isolates] == [x for x in B if x in self.isolates])]\n",
    "        temp=[]\n",
    "        self.all_edges=[]\n",
    "        for edge in all_edges:\n",
    "            strx='==>'.join(['###'.join(edge[0]),'###'.join(edge[1])])\n",
    "            if strx not in temp:\n",
    "                temp.append(strx)\n",
    "                self.all_edges.append(edge)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_path_edges(node_seq):\n",
    "        '''\n",
    "            from node sequence to edges\n",
    "        '''\n",
    "        edges = list()\n",
    "        for first, second in zip(node_seq, node_seq[1:]):\n",
    "            edges.append(([x.name for x in first.get_terminals()], [x.name for x in second.get_terminals()]))\n",
    "        return edges\n",
    "\n",
    "    def get_rep_set_of_nodes(self, A):\n",
    "        '''\n",
    "            get representations of nodes\n",
    "        '''\n",
    "        idxs = [self.isolates.index(x) for x in A if x in self.isolates]\n",
    "        res = []\n",
    "        for arr in self.X[idxs, :]:#.toarray():\n",
    "            if len(res) == 0:\n",
    "                res = arr\n",
    "            else:\n",
    "                res = np.multiply(res, arr)\n",
    "        return res\n",
    "\n",
    "    def get_labels(self, from_labels, to_labels):\n",
    "        '''\n",
    "            Rules for chi2 labels\n",
    "        '''\n",
    "        if from_labels == to_labels:\n",
    "            return [0, 0]\n",
    "        if to_labels == 'R':\n",
    "            return [2, 0]\n",
    "        if from_labels == 'R':\n",
    "            return [0, 2]\n",
    "        if to_labels == 'I':\n",
    "            return [1, 0]\n",
    "        if from_labels == 'I':\n",
    "            return [0, 1]\n",
    "        if from_labels == 'S' and (not 'S' in to_labels):\n",
    "            if 'R' in to_labels:\n",
    "                return [2, 0]\n",
    "            else:\n",
    "                return [1, 0]\n",
    "        if to_labels == 'S' and (not 'S' in from_labels):\n",
    "            if 'R' in to_labels:\n",
    "                return [0, 2]\n",
    "            else:\n",
    "                return [0, 1]\n",
    "        return [0, 0]\n",
    "\n",
    "    def get_corpus_labels(self, ABDrug_triple):\n",
    "        '''\n",
    "            for a single edge betweeb A and B and for drug drug_idx it produces the gaines and losses and phenotype change\n",
    "        '''\n",
    "        gains_losses_corpus = []\n",
    "        A, B, drug = ABDrug_triple\n",
    "        A = [iso for iso in set(A) if iso in self.isolates]\n",
    "        B = [iso for iso in set(B) if iso in self.isolates]\n",
    "        x_parent = self.get_rep_set_of_nodes(A)\n",
    "        x_self = self.get_rep_set_of_nodes(B)\n",
    "        x_siblings = self.get_rep_set_of_nodes(list(set(A) - set(B)))\n",
    "        gain = ['gain_' + self.features[idx] for idx in list(np.where((x_self - x_parent) > 0)[0])]\n",
    "        loss = ['loss_' + self.features[idx] for idx in list(np.where((x_self - x_siblings) < 0)[0])]\n",
    "        # extract labels\n",
    "        sibling_labels = list(set([self.Y[self.isolates.index(iso)] for iso in set(A) - set(B)]))\n",
    "        self_labels = list(set([self.Y[self.isolates.index(iso)] for iso in B]))\n",
    "        sibling_labels.sort()\n",
    "        self_labels.sort()\n",
    "        label = '=>'.join([''.join(sibling_labels), ''.join(self_labels)])\n",
    "        temp = []\n",
    "        if len(gain) > 0:\n",
    "            temp += gain\n",
    "        if len(loss) > 0:\n",
    "            temp += loss\n",
    "        if len(temp) > 0:\n",
    "            gains_losses_corpus.append([label] + temp)\n",
    "        return gains_losses_corpus\n",
    "\n",
    "    def generate_features_chi2(self):\n",
    "        '''\n",
    "        Generate chi2 selected features over the edges and store them for each separate drug\n",
    "        :return:\n",
    "        '''\n",
    "        for drug_idx in range(0, 5):\n",
    "            print(self.drugs[drug_idx])\n",
    "            X = FileUtility.load_sparse_csr(self.saving_path + '_'.join([self.drugs[drug_idx], 'gainlosses', 'X.npz']))\n",
    "            features = FileUtility.load_list(\n",
    "                self.saving_path + '_'.join([self.drugs[drug_idx], 'gainlosses', 'features']))\n",
    "            labels = FileUtility.load_list(self.saving_path + '_'.join([self.drugs[drug_idx], 'gainlosses', 'lables']))\n",
    "            label_map = {'S=>R': 1, 'S=>I': 0, 'S=>IR': 0, 'I=>R': 0, 'IS=>R': 0}\n",
    "            # label_map={'S=>R':2,'S=>I':1,'S=>IR':2,'I=>R':2,'IR=>I':1,'IR=>R':2,'IS=>R':2,'IS=>I':1,'RS=>I':1,'RS=>R':2,'IRS=>I':1,'IRS=>R':2}\n",
    "            # label_map={'S=>R':2,'S=>I':1,'S=>IR':2,'I=>R':2,'IS=>R':2}\n",
    "            row_values = [label_map[x] if x in label_map else 0 for x in labels]\n",
    "            two_idxs = [idx for idx, x in enumerate(row_values) if x == 2]\n",
    "            chi2_label = [1 if x > 0 else 0 for x in row_values]\n",
    "            # X=X.toarray()\n",
    "            # X[two_idxs,:]=X[two_idxs,:]*2\n",
    "            #X=csr_matrix(X)\n",
    "            CHI2 = Chi2Analysis(X, chi2_label, feature_names=features)\n",
    "            CHI2.extract_features_fdr(self.resulting_path + '_'.join(self.feature_list) + self.drugs[drug_idx] + '.txt', N=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nwk='test_data/test_file.nwk'\n",
    "X=np.loadtxt('test_data/test_data.txt')\n",
    "Y=FileUtility.load_list('test_data/test_labels')\n",
    "feature_list=FileUtility.load_list('test_data/test_features')\n",
    "sample_list=['A','B','C','D','E','F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PCHI2=PhyloChi2(nwk, X, Y, feature_list, sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 8/8 [00:00<00:00, 28268.27it/s]\u001b[A"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/net/sgi/metagenomics/projects/pseudo_genomics/results/amr_toolkit/results/feature_selection/phylochi2/drug_gainlosses_X.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-3096c24f5ce4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPCHI2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_parallel_gainloss_data_for_drug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drug'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-d3e9598f13c6>\u001b[0m in \u001b[0;36mgenerate_parallel_gainloss_data_for_drug\u001b[0;34m(self, drug, num_p)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mTF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         FileUtility.save_sparse_csr(self.saving_path + '_'.join([drug, 'gainlosses', 'X']),\n\u001b[0;32m---> 61\u001b[0;31m                                     TF.tf_vec)\n\u001b[0m\u001b[1;32m     62\u001b[0m         FileUtility.save_list(self.saving_path + '_'.join([drug, 'gainlosses', 'features']),\n\u001b[1;32m     63\u001b[0m                               TF.feature_names)\n",
      "\u001b[0;32m/nfs/datm/asgari/dissertation/git_repos/amrprediction/utility/file_utility.py\u001b[0m in \u001b[0;36msave_sparse_csr\u001b[0;34m(filename, array)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_sparse_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         np.savez(filename,data = array.data ,indices=array.indices,\n\u001b[0;32m---> 51\u001b[0;31m                  indptr =array.indptr, shape=array.shape )\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_sparse_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mounts/Users/student/asgari/.local/lib/python3.4/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msavez\u001b[0;34m(file, *args, **kwds)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \"\"\"\n\u001b[0;32m--> 593\u001b[0;31m     \u001b[0m_savez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mounts/Users/student/asgari/.local/lib/python3.4/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m_savez\u001b[0;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZIP_STORED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m     \u001b[0mzipf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;31m# Stage arrays in a temporary file on disk, before writing to zip.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mounts/Users/student/asgari/.local/lib/python3.4/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mzipfile_factory\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allowZip64'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0mmodeDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'r'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'r+b'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/net/sgi/metagenomics/projects/pseudo_genomics/results/amr_toolkit/results/feature_selection/phylochi2/drug_gainlosses_X.npz'"
     ]
    }
   ],
   "source": [
    "PCHI2.generate_parallel_gainloss_data_for_drug('drug',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
