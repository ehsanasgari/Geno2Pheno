{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from utility.file_utility import FileUtility\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_cv_res(filename):\n",
    "    [label_set, conf, best_score_, best_estimator_,cv_results_, best_params_, pred]=FileUtility.load_obj(filename)\n",
    "    res=dict()\n",
    "    idx=np.argmax(cv_results_['mean_test_f1_macro'])\n",
    "    res['f1_macro*']=np.round(cv_results_['mean_test_f1_macro'][idx],2)\n",
    "    res['f1_macro']=str(np.round(cv_results_['mean_test_f1_macro'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_f1_macro'][idx],2))\n",
    "    res['f1_micro']=str(np.round(cv_results_['mean_test_f1_micro'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_f1_micro'][idx],2))\n",
    "    res['precision_micro']=str(np.round(cv_results_['mean_test_precision_micro'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_precision_micro'][idx],2))\n",
    "    res['precision_macro']=str(np.round(cv_results_['mean_test_precision_macro'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_precision_macro'][idx],2))\n",
    "    res['recall_micro']=str(np.round(cv_results_['mean_test_recall_micro'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_recall_micro'][idx],2))\n",
    "    res['recall_macro']=str(np.round(cv_results_['mean_test_recall_macro'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_recall_macro'][idx],2))\n",
    "    res['accuracy']=str(np.round(cv_results_['mean_test_accuracy'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_accuracy'][idx],2))\n",
    "    res['tnr']=str(np.round(cv_results_['mean_test_tnr'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_tnr'][idx],2))\n",
    "    res['scores_p_0']=str(np.round(cv_results_['mean_test_scores_p_0'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_scores_p_0'][idx],2))\n",
    "    res['scores_r_0']=str(np.round(cv_results_['mean_test_scores_r_0'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_scores_r_0'][idx],2))\n",
    "    res['scores_f_1_0']=str(np.round(cv_results_['mean_test_scores_f_1_0'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_scores_f_1_0'][idx],2))\n",
    "    res['scores_f_1_1']=str(np.round(cv_results_['mean_test_scores_f_1_1'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_scores_f_1_1'][idx],2))\n",
    "    res['scores_p_1']=str(np.round(cv_results_['mean_test_scores_p_1'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_scores_p_1'][idx],2))\n",
    "    res['scores_r_1']=str(np.round(cv_results_['mean_test_scores_r_1'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_scores_r_1'][idx],2)) \n",
    "    res['file']=file\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_table_from_files(files):\n",
    "    table = {'classifier': [], 'drug': [], 'feature':[],'f1_macro':[],'precision_micro':[],'precision_macro':[],'recall_micro':[],'recall_macro':[],'accuracy':[],'tnr':[],'scores_p_0':[],'scores_r_0':[],'scores_f_1_0':[],'scores_p_1':[],'scores_r_1':[],'scores_f_1_1':[]}\n",
    "    drugs=['Ceftazidim','Tobramycin','Meropenem','Colistin','Ciprofloxacin']\n",
    "    for file in files:        \n",
    "        drug_feature_classifier=file.split('/')[-1].replace('.pickle','').split('_')\n",
    "        for drug in drugs:\n",
    "            if drug in drug_feature_classifier[0]:\n",
    "                drug_feature_classifier.insert(0,drug)\n",
    "                drug_feature_classifier[1]=drug_feature_classifier[1].replace(drug,'')\n",
    "                drug_feature_classifier=[drug_feature_classifier[0],'_'.join(drug_feature_classifier[1:-1]),drug_feature_classifier[-1]]\n",
    "                res=get_cv_res(file)\n",
    "                for key in table:\n",
    "                    if key=='classifier':\n",
    "                        table['classifier'].append(drug_feature_classifier[-1])\n",
    "                    elif key=='drug':\n",
    "                        table['drug'].append(drug_feature_classifier[0])\n",
    "                    elif key=='feature':\n",
    "                        table['feature'].append(drug_feature_classifier[1])\n",
    "                    else:\n",
    "                        table[key].append(res[key])\n",
    "    return pd.DataFrame(data=table,columns=['drug', 'feature','classifier','f1_macro','scores_r_0','accuracy','tnr','precision_micro','precision_macro','recall_micro','recall_macro','scores_p_0','scores_r_0','scores_f_1_0','scores_p_1','scores_r_1','scores_f_1_1'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path2res='/mounts/data/proj/asgari/dissertation/git_repos/amr_results/results/classifications_standard/'\n",
    "files_block=FileUtility.recursive_glob(path2res,'*.pickle')\n",
    "path2res='/mounts/data/proj/asgari/dissertation/git_repos/amr_results/results/classifications_block/'\n",
    "files_std=FileUtility.recursive_glob(path2res,'*.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/Users/student/asgari/.local/lib/python3.4/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator LinearSVC from version 0.19.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/mounts/Users/student/asgari/.local/lib/python3.4/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.19.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/mounts/Users/student/asgari/.local/lib/python3.4/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.19.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/mounts/Users/student/asgari/.local/lib/python3.4/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 0.19.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "writer = pd.ExcelWriter('output.xlsx')\n",
    "get_table_from_files(files_block).to_excel(writer,'block')\n",
    "get_table_from_files(files_std).to_excel(writer,'standard')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
