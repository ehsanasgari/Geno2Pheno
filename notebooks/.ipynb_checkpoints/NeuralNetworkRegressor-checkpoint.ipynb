{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from data_access.data_access_utility import ABRDataAccess\n",
    "from classifier.classical_classifiers import SVM, RFClassifier, KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data access created..\n",
      "@@@/mounts/data/proj/asgari/dissertation/datasets/deepbio/pseudomonas/data_v3/snps_nonsyn_trimmed_feature_vect.npz\n",
      "@@@/mounts/data/proj/asgari/dissertation/datasets/deepbio/pseudomonas/data_v3/phylogenetic_feature_vect.npz\n",
      "@@@/mounts/data/proj/asgari/dissertation/datasets/deepbio/pseudomonas/data_v3/continous_mic_vals_feature_vect.npz\n"
     ]
    }
   ],
   "source": [
    "feature_list=['snps_nonsyn_trimmed','phylogenetic','continous_mic_vals']\n",
    "ABRAccess=ABRDataAccess('/mounts/data/proj/asgari/dissertation/datasets/deepbio/pseudomonas/data_v3/',feature_list)\n",
    "X,Y,features=ABRAccess.get_xy_multidrug_prediction_mats()\n",
    "temp=X[:,5::].toarray()\n",
    "Y=X[:,0:5].toarray()\n",
    "X=temp\n",
    "labels_list=features[0:5]\n",
    "features=features[5::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from utility.file_utility import FileUtility\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from gensim.models.wrappers import FastText\n",
    "import itertools\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "class DNNAMR(object):\n",
    "    \n",
    "    def __init__(self, X,Y, model_arch=[500]):\n",
    "        # rep. X\n",
    "        self.X=X\n",
    "        # encoding Y\n",
    "        self.C=Y.shape[1]\n",
    "        self.Y=Y\n",
    "        # model's arch\n",
    "        self.model_arch=model_arch\n",
    "    \n",
    "    def get_MLP_model(self):\n",
    "        # creating the model\n",
    "        model = Sequential()\n",
    "        for layer_idx, h_layer_size in enumerate(self.model_arch):\n",
    "            if layer_idx==0:\n",
    "                model.add(Dense(h_layer_size, input_dim=self.X.shape[1], activation='relu'))\n",
    "            else:\n",
    "                if h_layer_size < 1:\n",
    "                    model.add(Dropout(h_layer_size))\n",
    "                else:\n",
    "                    model.add(Dense(h_layer_size, activation='relu'))\n",
    "        model.add(Dense(self.C))        \n",
    "        # Compile model\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def cross_validation(self, result_filename, gpu_dev='3', n_fold=5, epochs=100, batch_size=5, model_strct='mlp', pretrained_model=False, trainable=False):\n",
    "\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_dev\n",
    "        \n",
    "        skf = KFold(n_splits=n_fold, shuffle=True)\n",
    "        \n",
    "        for train_index, valid_index in skf.split(self.X, self.Y):\n",
    "            print ('\\n Evaluation on a new fold is now get started ..')\n",
    "            X_train=self.X[train_index,:]\n",
    "            y_train=self.Y[train_index,:]\n",
    "            X_valid=self.X[valid_index,:]\n",
    "            y_valid=self.Y[valid_index,:]\n",
    "            \n",
    "            if pretrained_model:\n",
    "                model=self.get_pretrained_model(model_strct, trainable)\n",
    "            else:\n",
    "                if model_strct=='mlp':\n",
    "                    model=self.get_MLP_model()\n",
    "                if model_strct=='embmlp':\n",
    "                    model=self.get_EMB_MLP_model()\n",
    "            \n",
    "            # fitting\n",
    "            history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,shuffle=True, validation_data=(X_valid, y_valid), verbose=0)\n",
    "            \n",
    "        self.history=history\n",
    "        self.model=model\n",
    "        \n",
    "        \n",
    "        history_dict = history.history\n",
    "        loss_values = history_dict['loss']\n",
    "        val_loss_values = history_dict['val_loss']\n",
    "        epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "        if pretrained_model:\n",
    "            model_strct='pretrained'\n",
    "            #print (model.summary())\n",
    "        \n",
    "        weights=[]\n",
    "        for x in model.layers:\n",
    "            weights.append(x.get_weights())\n",
    "        \n",
    "        FileUtility.save_obj('_'.join([result_filename, 'layers', model_strct,'-'.join([str(x) for x in self.model_arch])]), (weights,(loss_values, val_loss_values, epochs)))\n",
    "\n",
    "    @staticmethod\n",
    "    def load_history(filename, fileout):\n",
    "        [latex_line, p_micro, r_micro, f1_micro, p_macro, r_macro, f1_macro, history]=FileUtility.load_obj(filename)\n",
    "        (loss_values, val_loss_values, epochs)=history\n",
    "        matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "        matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "        matplotlib.rcParams['mathtext.fontset'] = 'custom'\n",
    "        matplotlib.rcParams['mathtext.rm'] = 'Bitstream Vera Sans'\n",
    "        matplotlib.rcParams['mathtext.it'] = 'Bitstream Vera Sans:italic'\n",
    "        matplotlib.rcParams['mathtext.bf'] = 'Bitstream Vera Sans:bold'\n",
    "        matplotlib.rcParams[\"axes.edgecolor\"] = \"black\"\n",
    "        matplotlib.rcParams[\"axes.linewidth\"] = 0.6\n",
    "        plt.rc('text', usetex=True)\n",
    "        plt.plot(epochs, loss_values, 'ro', label='Loss for train set')\n",
    "        plt.plot(epochs, val_loss_values, 'b+', label='Loss for test set')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(loc=1, prop={'size': 8},ncol=1, edgecolor='black', facecolor='white', frameon=True)\n",
    "        plt.title('Loss with respect to the number of epochs for train and test sets')\n",
    "        plt.savefig(fileout+'.pdf')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def make_activation_function(file_name, X, last_layer=None):\n",
    "        pretrained_weights=FileUtility.load_obj(file_name)\n",
    "        if last_layer:\n",
    "            h_sizes=[float(x) for x in file_name.split('/')[-1].split('_')[3].split('-')]+[last_layer]\n",
    "        else:\n",
    "            h_sizes=[float(x) for x in file_name.split('/')[-1].split('_')[3].split('-')]\n",
    "        model = Sequential()\n",
    "        for layer_idx, h_layer_size in enumerate(h_sizes):\n",
    "            if layer_idx==0:\n",
    "                model.add(Dense(int(h_layer_size), input_dim=X.shape[1], weights=pretrained_weights[0],  activation='relu'))\n",
    "            else:\n",
    "                if h_layer_size < 1:\n",
    "                    model.add(Dropout(h_layer_size, weights=pretrained_weights[layer_idx]))\n",
    "                else:\n",
    "                    if layer_idx == len(h_sizes)-1 and last_layer:\n",
    "                        model.add(Dense(int(h_layer_size), weights=pretrained_weights[layer_idx], activation='sigmoid'))\n",
    "                    else:\n",
    "                        model.add(Dense(int(h_layer_size), weights=pretrained_weights[layer_idx], activation='relu'))\n",
    "        activations = model.predict(X)\n",
    "        np.savetxt(file_name.replace(file_name.split('/')[-1].split('_')[0],'activationlayer'),activations)\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DNN=DNNAMR(X,Y,model_arch=[1000,0.2,500,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluation on a new fold is now get started ..\n",
      "\n",
      " Evaluation on a new fold is now get started ..\n",
      "\n",
      " Evaluation on a new fold is now get started ..\n"
     ]
    }
   ],
   "source": [
    "DNN.cross_validation('../results/classification/dnn/', gpu_dev='3', n_fold=3, epochs=30, batch_size=5, model_strct='mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "history=DNN.history\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAESCAYAAAAMifkAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIj6fxduDGKrB5CfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f812433cb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'custom'\n",
    "matplotlib.rcParams['mathtext.rm'] = 'Bitstream Vera Sans'\n",
    "matplotlib.rcParams['mathtext.it'] = 'Bitstream Vera Sans:italic'\n",
    "matplotlib.rcParams['mathtext.bf'] = 'Bitstream Vera Sans:bold'\n",
    "matplotlib.rcParams[\"axes.edgecolor\"] = \"black\"\n",
    "matplotlib.rcParams[\"axes.linewidth\"] = 0.6\n",
    "plt.rc('text', usetex=True)\n",
    "plt.plot(epochs, loss_values, 'ro', label='Loss for train set')\n",
    "plt.plot(epochs, val_loss_values, 'b+', label='Loss for test set')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc=1, prop={'size': 8},ncol=1, edgecolor='black', facecolor='white', frameon=True)\n",
    "plt.title('Loss with respect to the number of epochs for train and test sets')\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Y_hat=DNN.model.predict_on_batch(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01538462,  0.03113173,  0.00392157,  0.49993896,  0.06227106],\n",
       "       [ 0.00757021,  0.01550482,  0.49803922,  0.01550482,  0.003663  ],\n",
       "       [ 0.0017094 ,  0.00378464,  0.01176471,  0.49993896,  0.01538462],\n",
       "       ..., \n",
       "       [ 0.00757021,  0.00378464,  0.02745098,  0.00378464,  0.01538462],\n",
       "       [ 0.12478632,  0.12489318,  0.02745098,  0.49993896,  0.4998779 ],\n",
       "       [ 0.12478632,  0.24990844,  0.02745098,  0.49993896,  0.4998779 ]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
